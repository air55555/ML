{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "es8f2Mc7ecDF",
    "colab_type": "text"
   },
   "source": [
    "<h1>2b. Machine Learning using tf.estimator </h1>\n",
    "\n",
    "In this notebook, we will create a machine learning model using tf.estimator and evaluate its performance.  The dataset is rather small (7700 samples), so we can do it all in-memory.  We will also simply pass the raw data in as-is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "BaLED83uecDL",
    "colab_type": "code",
    "outputId": "420d1e38-1bbe-467e-9f38-227cefefe03e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.542700289317E12,
     "user_tz": -180.0,
     "elapsed": 71740.0,
     "user": {
      "displayName": "Al Rаmashkа",
      "photoUrl": "https://lh4.googleusercontent.com/-nXK4SF90QQk/AAAAAAAAAAI/AAAAAAAACCk/JH7qGa0qfC0/s64/photo.jpg",
      "userId": "01742665280174830607"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mspacy 2.0.16 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-colab 0.0.1a1 has requirement six~=1.11.0, but you'll have six 1.10.0 which is incompatible.\u001b[0m\n",
      "1.12.0\n",
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "!pip install -q datalab\n",
    "import datalab.bigquery as bq\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "print(tf.__version__)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# In CSV, label is the first column, after the features, followed by the key\n",
    "CSV_COLUMNS = ['fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key']\n",
    "FEATURES = CSV_COLUMNS[1:len(CSV_COLUMNS) - 1]\n",
    "LABEL = CSV_COLUMNS[0]\n",
    "df_train=pd.read_csv('drive/My Drive/Colab Notebooks/taxi-train.csv',header = None, names = CSV_COLUMNS)\n",
    "#df_train = pd.read_csv('./taxi-train.csv', header = None, names = CSV_COLUMNS)\n",
    "df_valid = pd.read_csv('drive/My Drive/Colab Notebooks/taxi-valid.csv', header = None, names = CSV_COLUMNS)\n",
    "#df_test = pd.read_csv('./taxi-test.csv', header = None, names = CSV_COLUMNS)\n",
    "\n",
    "def make_train_input_fn(df, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df,\n",
    "    y = df[LABEL],\n",
    "    batch_size = 128,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000\n",
    "  )\n",
    "\n",
    "def make_feature_cols():\n",
    "  input_columns = [tf.feature_column.numeric_column(k) for k in FEATURES]\n",
    "  return input_columns\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "OUTDIR = 'drive/My Drive/Colab Notebooks/taxi_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "model = tf.estimator.LinearRegressor(\n",
    "      feature_columns = make_feature_cols(), model_dir = OUTDIR)\n",
    "\n",
    "model.train(input_fn = make_train_input_fn(df_train, num_epochs = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "BGOOQXZvecDZ",
    "colab_type": "text"
   },
   "source": [
    "Read data created in the previous chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "sf732ny5ecDd",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXcDlOP7GWTJ",
    "colab_type": "text"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDIc7VLRGWwo",
    "colab_type": "text"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "Bxc840fBecDm",
    "colab_type": "text"
   },
   "source": [
    "<h2> Train and eval input functions to read from Pandas Dataframe </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "m4lF1ClZecDp",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "v6EP1s_vecDy",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def make_eval_input_fn(df):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df,\n",
    "    y = df[LABEL],\n",
    "    batch_size = 128,\n",
    "    shuffle = False,\n",
    "    queue_capacity = 1000\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "LK_IJFrRecD5",
    "colab_type": "text"
   },
   "source": [
    "Our input function for predictions is the same except we don't provide a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "54DqgNzMecD7",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def make_prediction_input_fn(df):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df,\n",
    "    y = None,\n",
    "    batch_size = 128,\n",
    "    shuffle = False,\n",
    "    queue_capacity = 1000\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "TELvDgGoecEF",
    "colab_type": "text"
   },
   "source": [
    "### Create feature columns for estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "qSDDiplZecEL",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "hRd06MJZecEU",
    "colab_type": "text"
   },
   "source": [
    "<h3> Linear Regression with tf.Estimator framework </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "Dx8DbbL7ecEY",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606.0
    },
    "outputId": "eaf87c66-c58f-435d-c03b-f64d7e5a5379",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.542704419078E12,
     "user_tz": -180.0,
     "elapsed": 4425.0,
     "user": {
      "displayName": "Al Rаmashkа",
      "photoUrl": "https://lh4.googleusercontent.com/-nXK4SF90QQk/AAAAAAAAAAI/AAAAAAAACCk/JH7qGa0qfC0/s64/photo.jpg",
      "userId": "01742665280174830607"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'drive/My Drive/Colab Notebooks/taxi_trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8dc4b005c0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into drive/My Drive/Colab Notebooks/taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 19329.354, step = 1\n",
      "INFO:tensorflow:global_step/sec: 207.321\n",
      "INFO:tensorflow:loss = 11708.234, step = 101 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.636\n",
      "INFO:tensorflow:loss = 18430.55, step = 201 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.384\n",
      "INFO:tensorflow:loss = 4932.778, step = 301 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.586\n",
      "INFO:tensorflow:loss = 16669.434, step = 401 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.019\n",
      "INFO:tensorflow:loss = 12054.389, step = 501 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.817\n",
      "INFO:tensorflow:loss = 22110.254, step = 601 (0.326 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 608 into drive/My Drive/Colab Notebooks/taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 133.85616.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7f8dc4b00390>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "-48uTLo9ecEh",
    "colab_type": "text"
   },
   "source": [
    "Evaluate on the validation data (we should defer using the test data to after we have selected a final model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "rZJswbXIecEn",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219.0
    },
    "outputId": "c1667a56-8fe1-4219-b5bc-413057a97259",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.542704428536E12,
     "user_tz": -180.0,
     "elapsed": 1419.0,
     "user": {
      "displayName": "Al Rаmashkа",
      "photoUrl": "https://lh4.googleusercontent.com/-nXK4SF90QQk/AAAAAAAAAAI/AAAAAAAACCk/JH7qGa0qfC0/s64/photo.jpg",
      "userId": "01742665280174830607"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-20-09:00:27\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks/taxi_trained/model.ckpt-608\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-20-09:00:28\n",
      "INFO:tensorflow:Saving dict for global step 608: average_loss = 109.49838, global_step = 608, label/mean = 11.666427, loss = 13022.486, prediction/mean = 10.843966\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 608: drive/My Drive/Colab Notebooks/taxi_trained/model.ckpt-608\n",
      "RMSE on dataset = 10.464147567749023\n"
     ]
    }
   ],
   "source": [
    "def print_rmse(model, df):\n",
    "  metrics = model.evaluate(input_fn = make_eval_input_fn(df))\n",
    "  print('RMSE on dataset = {}'.format(np.sqrt(metrics['average_loss'])))\n",
    "print_rmse(model, df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "YVAlJflyecEu",
    "colab_type": "text"
   },
   "source": [
    "This is nowhere near our benchmark (RMSE of $6 or so on this data), but it serves to demonstrate what TensorFlow code looks like.  Let's use this model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "_BM8DXqoecEv",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209.0
    },
    "outputId": "741011bf-4677-4785-f417-f5a6af923097",
    "executionInfo": {
     "status": "error",
     "timestamp": 1.542704504089E12,
     "user_tz": -180.0,
     "elapsed": 677.0,
     "user": {
      "displayName": "Al Rаmashkа",
      "photoUrl": "https://lh4.googleusercontent.com/-nXK4SF90QQk/AAAAAAAAAAI/AAAAAAAACCk/JH7qGa0qfC0/s64/photo.jpg",
      "userId": "01742665280174830607"
     }
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2c3e630ecf89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_prediction_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_prediction_input_fn' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "predictions = model.predict(input_fn = make_prediction_input_fn(df_test))\n",
    "for items in predictions:\n",
    "  print(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "ijxbcLa4ecE1",
    "colab_type": "text"
   },
   "source": [
    "This explains why the RMSE was so high -- the model essentially predicts the same amount for every trip.  Would a more complex model help? Let's try using a deep neural network.  The code to do this is quite straightforward as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "So4J6NTfecE4",
    "colab_type": "text"
   },
   "source": [
    "<h3> Deep Neural Network regression </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "ppAKhqnmecE6",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2774.0
    },
    "outputId": "ab5911cd-a5c9-41da-e645-19950bb88825",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.542704533207E12,
     "user_tz": -180.0,
     "elapsed": 24455.0,
     "user": {
      "displayName": "Al Rаmashkа",
      "photoUrl": "https://lh4.googleusercontent.com/-nXK4SF90QQk/AAAAAAAAAAI/AAAAAAAACCk/JH7qGa0qfC0/s64/photo.jpg",
      "userId": "01742665280174830607"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'drive/My Drive/Colab Notebooks/taxi_trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8dbf7d64e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into drive/My Drive/Colab Notebooks/taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 68153.05, step = 1\n",
      "INFO:tensorflow:global_step/sec: 208.307\n",
      "INFO:tensorflow:loss = 31902.652, step = 101 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.147\n",
      "INFO:tensorflow:loss = 21373.285, step = 201 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.263\n",
      "INFO:tensorflow:loss = 18970.328, step = 301 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.905\n",
      "INFO:tensorflow:loss = 16664.008, step = 401 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.839\n",
      "INFO:tensorflow:loss = 24131.908, step = 501 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.444\n",
      "INFO:tensorflow:loss = 15262.973, step = 601 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.568\n",
      "INFO:tensorflow:loss = 15278.247, step = 701 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.233\n",
      "INFO:tensorflow:loss = 12201.022, step = 801 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.059\n",
      "INFO:tensorflow:loss = 12067.717, step = 901 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.882\n",
      "INFO:tensorflow:loss = 22753.484, step = 1001 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.334\n",
      "INFO:tensorflow:loss = 13614.971, step = 1101 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.935\n",
      "INFO:tensorflow:loss = 19035.797, step = 1201 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.279\n",
      "INFO:tensorflow:loss = 14316.528, step = 1301 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.514\n",
      "INFO:tensorflow:loss = 22854.857, step = 1401 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.654\n",
      "INFO:tensorflow:loss = 22109.621, step = 1501 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.446\n",
      "INFO:tensorflow:loss = 20468.004, step = 1601 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.477\n",
      "INFO:tensorflow:loss = 17361.758, step = 1701 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.872\n",
      "INFO:tensorflow:loss = 12273.972, step = 1801 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.811\n",
      "INFO:tensorflow:loss = 21815.93, step = 1901 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.312\n",
      "INFO:tensorflow:loss = 18938.152, step = 2001 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.336\n",
      "INFO:tensorflow:loss = 10238.969, step = 2101 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.762\n",
      "INFO:tensorflow:loss = 17681.371, step = 2201 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.085\n",
      "INFO:tensorflow:loss = 11328.72, step = 2301 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.644\n",
      "INFO:tensorflow:loss = 15184.992, step = 2401 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.469\n",
      "INFO:tensorflow:loss = 14476.549, step = 2501 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.067\n",
      "INFO:tensorflow:loss = 17531.5, step = 2601 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.351\n",
      "INFO:tensorflow:loss = 12268.885, step = 2701 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.165\n",
      "INFO:tensorflow:loss = 10011.844, step = 2801 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.195\n",
      "INFO:tensorflow:loss = 23024.195, step = 2901 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.984\n",
      "INFO:tensorflow:loss = 14752.151, step = 3001 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.579\n",
      "INFO:tensorflow:loss = 21231.234, step = 3101 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.501\n",
      "INFO:tensorflow:loss = 17709.77, step = 3201 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.599\n",
      "INFO:tensorflow:loss = 16978.812, step = 3301 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.812\n",
      "INFO:tensorflow:loss = 16037.776, step = 3401 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.478\n",
      "INFO:tensorflow:loss = 18518.906, step = 3501 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.88\n",
      "INFO:tensorflow:loss = 18169.658, step = 3601 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.784\n",
      "INFO:tensorflow:loss = 20339.203, step = 3701 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.672\n",
      "INFO:tensorflow:loss = 8536.285, step = 3801 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.527\n",
      "INFO:tensorflow:loss = 8076.782, step = 3901 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.396\n",
      "INFO:tensorflow:loss = 17171.803, step = 4001 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.028\n",
      "INFO:tensorflow:loss = 20329.246, step = 4101 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.392\n",
      "INFO:tensorflow:loss = 20981.205, step = 4201 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.544\n",
      "INFO:tensorflow:loss = 14805.947, step = 4301 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.229\n",
      "INFO:tensorflow:loss = 7606.497, step = 4401 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.243\n",
      "INFO:tensorflow:loss = 14603.516, step = 4501 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.996\n",
      "INFO:tensorflow:loss = 12304.859, step = 4601 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.085\n",
      "INFO:tensorflow:loss = 6420.5166, step = 4701 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.002\n",
      "INFO:tensorflow:loss = 18059.967, step = 4801 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.978\n",
      "INFO:tensorflow:loss = 18000.564, step = 4901 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.855\n",
      "INFO:tensorflow:loss = 15247.381, step = 5001 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.82\n",
      "INFO:tensorflow:loss = 13815.373, step = 5101 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.467\n",
      "INFO:tensorflow:loss = 14232.663, step = 5201 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.005\n",
      "INFO:tensorflow:loss = 10083.123, step = 5301 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.398\n",
      "INFO:tensorflow:loss = 14910.784, step = 5401 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.631\n",
      "INFO:tensorflow:loss = 14411.605, step = 5501 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.225\n",
      "INFO:tensorflow:loss = 12794.389, step = 5601 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.207\n",
      "INFO:tensorflow:loss = 13464.752, step = 5701 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.952\n",
      "INFO:tensorflow:loss = 10655.892, step = 5801 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.063\n",
      "INFO:tensorflow:loss = 10990.338, step = 5901 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.471\n",
      "INFO:tensorflow:loss = 11418.041, step = 6001 (0.350 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6071 into drive/My Drive/Colab Notebooks/taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2867.117.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-20-09:02:12\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks/taxi_trained/model.ckpt-6071\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-20-09:02:12\n",
      "INFO:tensorflow:Saving dict for global step 6071: average_loss = 135.63354, global_step = 6071, label/mean = 11.666427, loss = 16130.704, prediction/mean = 6.4843574\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6071: drive/My Drive/Colab Notebooks/taxi_trained/model.ckpt-6071\n",
      "RMSE on dataset = 11.646181106567383\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "model = tf.estimator.DNNRegressor(hidden_units = [32, 8, 2],\n",
    "      feature_columns = make_feature_cols(), model_dir = OUTDIR)\n",
    "model.train(input_fn = make_train_input_fn(df_train, num_epochs = 100));\n",
    "print_rmse(model, df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "iHALBdEHecFG",
    "colab_type": "text"
   },
   "source": [
    "We are not beating our benchmark with either model ... what's up?  Well, we may be using TensorFlow for Machine Learning, but we are not yet using it well.  That's what the rest of this course is about!\n",
    "\n",
    "But, for the record, let's say we had to choose between the two models. We'd choose the one with the lower validation error. Finally, we'd measure the RMSE on the test data with this chosen model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "kEXiMW3_ecFI",
    "colab_type": "text"
   },
   "source": [
    "<h2> Benchmark dataset </h2>\n",
    "\n",
    "Let's do this on the benchmark dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "20sn90ITecFJ",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 870.0
    },
    "outputId": "4470cbd8-4fc9-4b99-b14c-31e3fcb4c7be",
    "executionInfo": {
     "status": "error",
     "timestamp": 1.542704334366E12,
     "user_tz": -180.0,
     "elapsed": 3784.0,
     "user": {
      "displayName": "Al Rаmashkа",
      "photoUrl": "https://lh4.googleusercontent.com/-nXK4SF90QQk/AAAAAAAAAAI/AAAAAAAACCk/JH7qGa0qfC0/s64/photo.jpg",
      "userId": "01742665280174830607"
     }
    }
   },
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a781074c56ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datalab/bigquery/_query.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sql, context, values, udfs, data_sources, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m       \"\"\"\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m       \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatalab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datalab/context/_context.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mAn\u001b[0m \u001b[0minitialized\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshared\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mContext\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_project\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datalab/context/_utils.py\u001b[0m in \u001b[0;36mget_credentials\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No application credentials found. Perhaps you should sign in.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/datalab/context/_utils.py\u001b[0m in \u001b[0;36mget_credentials\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m   \"\"\"\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_scopes_if_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCREDENTIAL_SCOPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/auth/_default.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(scopes, request)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffective_project_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaultCredentialsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_HELP_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m: Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or\nexplicitly create credential and re-run the application. For more\ninformation, please see\nhttps://developers.google.com/accounts/docs/application-default-credentials."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import datalab.bigquery as bq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_query(phase, EVERY_N):\n",
    "  \"\"\"\n",
    "  phase: 1 = train 2 = valid\n",
    "  \"\"\"\n",
    "  base_query = \"\"\"\n",
    "SELECT\n",
    "  (tolls_amount + fare_amount) AS fare_amount,\n",
    "  CONCAT(STRING(pickup_datetime), STRING(pickup_longitude), STRING(pickup_latitude), STRING(dropoff_latitude), STRING(dropoff_longitude)) AS key,\n",
    "  DAYOFWEEK(pickup_datetime)*1.0 AS dayofweek,\n",
    "  HOUR(pickup_datetime)*1.0 AS hourofday,\n",
    "  pickup_longitude AS pickuplon,\n",
    "  pickup_latitude AS pickuplat,\n",
    "  dropoff_longitude AS dropofflon,\n",
    "  dropoff_latitude AS dropofflat,\n",
    "  passenger_count*1.0 AS passengers,\n",
    "FROM\n",
    "  [nyc-tlc:yellow.trips]\n",
    "WHERE\n",
    "  trip_distance > 0\n",
    "  AND fare_amount >= 2.5\n",
    "  AND pickup_longitude > -78\n",
    "  AND pickup_longitude < -70\n",
    "  AND dropoff_longitude > -78\n",
    "  AND dropoff_longitude < -70\n",
    "  AND pickup_latitude > 37\n",
    "  AND pickup_latitude < 45\n",
    "  AND dropoff_latitude > 37\n",
    "  AND dropoff_latitude < 45\n",
    "  AND passenger_count > 0\n",
    "  \"\"\"\n",
    "\n",
    "  if EVERY_N == None:\n",
    "    if phase < 2:\n",
    "      # Training\n",
    "      query = \"{0} AND ABS(HASH(pickup_datetime)) % 4 < 2\".format(base_query)\n",
    "    else:\n",
    "      # Validation\n",
    "      query = \"{0} AND ABS(HASH(pickup_datetime)) % 4 == {1}\".format(base_query, phase)\n",
    "  else:\n",
    "    query = \"{0} AND ABS(HASH(pickup_datetime)) % {1} == {2}\".format(base_query, EVERY_N, phase)\n",
    "    \n",
    "  return query\n",
    "\n",
    "query = create_query(2, 100000)\n",
    "df = bq.Query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "QMQewkr2ecFO",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "print_rmse(model, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "gs-WSXfeecFX",
    "colab_type": "text"
   },
   "source": [
    "RMSE on benchmark dataset is <b>9.41</b> (your results will vary because of random seeds).\n",
    "\n",
    "This is not only way more than our original benchmark of 6.00, but it doesn't even beat our distance-based rule's RMSE of 8.02.\n",
    "\n",
    "Fear not -- you have learned how to write a TensorFlow model, but not to do all the things that you will have to do to your ML model performant. We will do this in the next chapters. In this chapter though, we will get our TensorFlow model ready for these improvements.\n",
    "\n",
    "In a software sense, the rest of the labs in this chapter will be about refactoring the code so that we can improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "dlnfGF-secFc",
    "colab_type": "text"
   },
   "source": [
    "## Challenge Exercise\n",
    "\n",
    "Create a neural network that is capable of finding the volume of a cylinder given the radius of its base (r) and its height (h). Assume that the radius and height of the cylinder are both in the range 0.5 to 2.0. Simulate the necessary training dataset.\n",
    "<p>\n",
    "Hint (highlight to see):\n",
    "<p style='color:white'>\n",
    "The input features will be r and h and the label will be $\\pi r^2 h$\n",
    "Create random values for r and h and compute V.\n",
    "Your dataset will consist of r, h and V.\n",
    "Then, use a DNN regressor.\n",
    "Make sure to generate enough data.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "id": "ku43mjbHecFh",
    "colab_type": "text"
   },
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of b_estimator.ipynb",
   "version": "0.3.2",
   "provenance": [
    {
     "file_id": "1jY3aRGciGc00dMmFXGesSzdsmW1bJper",
     "timestamp": 1.542623183533E12
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
